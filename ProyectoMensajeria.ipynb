{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42667c3",
   "metadata": {},
   "source": [
    "# Extracción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17018a6a",
   "metadata": {},
   "source": [
    "Cargue de libreria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48a344cf-dd22-40e6-b3f3-f675b2f3508f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\fabio\\onedrive\\desktop\\2do semestre\\ingenieria de datos\\proyectomensajeria\\myenv\\lib\\site-packages (2.0.41)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\fabio\\onedrive\\desktop\\2do semestre\\ingenieria de datos\\proyectomensajeria\\myenv\\lib\\site-packages (2.9.10)\n",
      "Requirement already satisfied: pandas in c:\\users\\fabio\\onedrive\\desktop\\2do semestre\\ingenieria de datos\\proyectomensajeria\\myenv\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\fabio\\onedrive\\desktop\\2do semestre\\ingenieria de datos\\proyectomensajeria\\myenv\\lib\\site-packages (from sqlalchemy) (3.2.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\fabio\\onedrive\\desktop\\2do semestre\\ingenieria de datos\\proyectomensajeria\\myenv\\lib\\site-packages (from sqlalchemy) (4.14.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\fabio\\onedrive\\desktop\\2do semestre\\ingenieria de datos\\proyectomensajeria\\myenv\\lib\\site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\fabio\\onedrive\\desktop\\2do semestre\\ingenieria de datos\\proyectomensajeria\\myenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\fabio\\onedrive\\desktop\\2do semestre\\ingenieria de datos\\proyectomensajeria\\myenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\fabio\\onedrive\\desktop\\2do semestre\\ingenieria de datos\\proyectomensajeria\\myenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\fabio\\onedrive\\desktop\\2do semestre\\ingenieria de datos\\proyectomensajeria\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sqlalchemy psycopg2-binary pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb34bc7b",
   "metadata": {},
   "source": [
    "Crear la conexión a PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25963d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Parámetros de conexión\n",
    "usuario = \"fabio\"         # ← Reemplaza por tu usuario de PostgreSQL\n",
    "clave = \"fabio\"        # ← Reemplaza por tu contraseña\n",
    "host = \"localhost\"             # ← Si está en tu máquina\n",
    "puerto = \"5432\"                # Puerto por defecto de PostgreSQL\n",
    "bd = \"ProyectoMensajeria\"         # Nombre de tu base de datos\n",
    "\n",
    "# Crear el motor de conexión\n",
    "engine = create_engine(f\"postgresql+psycopg2://{usuario}:{clave}@{host}:{puerto}/{bd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e5cb2",
   "metadata": {},
   "source": [
    "Ver qué tablas tiene la base\n",
    "\n",
    "Se realiza este paso para validar que tablas se cargaron de postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55ea535c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tablas disponibles en la base: ['admin_interface_theme', 'authtoken_token', 'areas_cliente', 'auth_user_groups', 'auth_group', 'auth_user', 'auth_user_user_permissions', 'ciudad', 'cliente', 'clientes_coordinador', 'clientes_mensajeroaquitoy', 'clientes_mensajeroaquitoy_clientes', 'clientes_datosmensajero', 'area', 'auth_permission', 'django_admin_log', 'clientes_usuarioaquitoy', 'departamento', 'django_content_type', 'django_migrations', 'django_session', 'mensajeria_tiponovedad', 'mensajeria_servicio', 'mensajeria_estado', 'mensajeria_novedadesservicio', 'mensajeria_origenservicio', 'mensajeria_tipopago', 'mensajeria_estadosservicio', 'mensajeria_destinoservicio', 'mensajeria_tipovehiculo', 'mensajeria_tiposervicio', 'sede', 'auth_group_permissions', 'tipo_cliente', 'mensajeria_documentoasociado']\n"
     ]
    }
   ],
   "source": [
    "# Ver tablas disponibles\n",
    "from sqlalchemy import inspect\n",
    "\n",
    "inspector = inspect(engine)\n",
    "tablas = inspector.get_table_names()\n",
    "print(\"Tablas disponibles en la base:\", tablas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47af0bdc",
   "metadata": {},
   "source": [
    "Extraer las tablas desde PostgreSQL a Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b3b8b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tablas de dimensiones\n",
    "df_cliente = pd.read_sql(\"SELECT * FROM cliente\", engine)\n",
    "df_sede = pd.read_sql(\"SELECT * FROM sede\", engine)\n",
    "df_ciudad = pd.read_sql(\"SELECT * FROM ciudad\", engine)\n",
    "df_tipo_cliente = pd.read_sql(\"SELECT * FROM tipo_cliente\", engine)\n",
    "df_mensajero = pd.read_sql(\"SELECT * FROM clientes_mensajeroaquitoy\", engine) \n",
    "df_tipo_vehiculo = pd.read_sql(\"SELECT * FROM mensajeria_tipovehiculo\", engine)\n",
    "df_estado = pd.read_sql(\"SELECT * FROM mensajeria_estado\", engine)\n",
    "df_tipo_novedad = pd.read_sql(\"SELECT * FROM mensajeria_tiponovedad\", engine)\n",
    "df_tipo_servicio = pd.read_sql(\"SELECT * FROM mensajeria_tiposervicio\", engine)\n",
    "df_tipo_pago = pd.read_sql(\"SELECT * FROM mensajeria_tipopago\", engine)\n",
    "df_auth_user = pd.read_sql(\"SELECT * FROM auth_user\", engine)\n",
    "\n",
    "# Tablas de hechos / procesos\n",
    "df_servicio = pd.read_sql(\"SELECT * FROM mensajeria_servicio\", engine)\n",
    "df_estados_servicio = pd.read_sql(\"SELECT * FROM mensajeria_estadosservicio\", engine)\n",
    "df_novedades = pd.read_sql(\"SELECT * FROM mensajeria_novedadesservicio\", engine)\n",
    "df_origen = pd.read_sql(\"SELECT * FROM mensajeria_origenservicio\", engine)\n",
    "df_destino = pd.read_sql(\"SELECT * FROM mensajeria_destinoservicio\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d43294",
   "metadata": {},
   "source": [
    "Transformacion de tablas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3532abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, time\n",
    "\n",
    "def calculate_time_diff(start_date_col, start_time_col, end_date_col, end_time_col):\n",
    "    mask = (\n",
    "        pd.notnull(start_date_col) & pd.notnull(start_time_col) & \n",
    "        pd.notnull(end_date_col) & pd.notnull(end_time_col)\n",
    "    )\n",
    "    start_dt = pd.to_datetime(\n",
    "        start_date_col[mask].astype(str) + ' ' + start_time_col[mask].astype(str), \n",
    "        format='mixed', errors='coerce'\n",
    "    )\n",
    "    end_dt = pd.to_datetime(\n",
    "        end_date_col[mask].astype(str) + ' ' + end_time_col[mask].astype(str), \n",
    "        format='mixed', errors='coerce'\n",
    "    )\n",
    "    diff = (end_dt - start_dt).dt.total_seconds() / 60\n",
    "    result = pd.Series(index=start_date_col.index, dtype='float64')\n",
    "    result[mask] = diff\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9713cbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión dim_hora creada con 24 filas.\n"
     ]
    }
   ],
   "source": [
    "# --- Dimensión: dim_hora ---\n",
    "hours = [time(h, 0, 0) for h in range(24)]\n",
    "dim_hora = pd.DataFrame(hours, columns=[\"Hora\"])\n",
    "dim_hora[\"ID_Hora\"] = dim_hora.index + 1\n",
    "dim_hora[\"Hour\"] = dim_hora[\"Hora\"].apply(lambda t: t.hour)\n",
    "\n",
    "def get_periodo(hour):\n",
    "    if 6 <= hour < 12:\n",
    "        return \"Mañana\"\n",
    "    elif 12 <= hour < 18:\n",
    "        return \"Tarde\"\n",
    "    elif 18 <= hour < 24:\n",
    "        return \"Noche\"\n",
    "    else:\n",
    "        return \"Madrugada\"\n",
    "\n",
    "def es_hora_laboral(hour):\n",
    "    return 8 <= hour < 18\n",
    "\n",
    "dim_hora[\"Periodo\"] = dim_hora[\"Hour\"].apply(get_periodo)\n",
    "dim_hora[\"HoraLaboral\"] = dim_hora[\"Hour\"].apply(es_hora_laboral)\n",
    "dim_hora = dim_hora[[\"ID_Hora\", \"Hora\", \"Hour\", \"Periodo\", \"HoraLaboral\"]]\n",
    "print(\"Dimensión dim_hora creada con\", len(dim_hora), \"filas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c40c9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión dim_fecha creada con 1096 filas.\n"
     ]
    }
   ],
   "source": [
    "# --- Dimensión: dim_fecha ---\n",
    "start_date = pd.to_datetime(\"2023-01-01\")\n",
    "end_date = pd.to_datetime(\"2025-12-31\")\n",
    "dates = pd.date_range(start=start_date, end=end_date, freq=\"D\")\n",
    "dim_fecha = pd.DataFrame(dates, columns=[\"Fecha\"])\n",
    "dim_fecha[\"ID_Fecha\"] = dim_fecha.index + 1\n",
    "dim_fecha[\"Year\"] = dim_fecha[\"Fecha\"].dt.year\n",
    "dim_fecha[\"Month\"] = dim_fecha[\"Fecha\"].dt.month\n",
    "dim_fecha[\"Day\"] = dim_fecha[\"Fecha\"].dt.day\n",
    "dim_fecha[\"MonthName\"] = dim_fecha[\"Fecha\"].dt.month_name(locale=\"es_ES\")\n",
    "dim_fecha[\"DayName\"] = dim_fecha[\"Fecha\"].dt.day_name(locale=\"es_ES\")\n",
    "dim_fecha[\"Quarter\"] = dim_fecha[\"Fecha\"].dt.quarter\n",
    "dim_fecha[\"IsWeekend\"] = dim_fecha[\"Fecha\"].dt.dayofweek.isin([5, 6])\n",
    "dim_fecha = dim_fecha[[\"ID_Fecha\", \"Fecha\", \"Year\", \"Month\", \"Day\", \"MonthName\", \"DayName\", \"Quarter\", \"IsWeekend\"]]\n",
    "print(\"Dimensión dim_fecha creada con\", len(dim_fecha), \"filas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "021532de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas después del merge con sede: ['id', 'direccion_origen', 'cliente_id_origen', 'ciudad_id_origen', 'sede_id', 'nombre', 'direccion_sede', 'telefono', 'nombre_contacto', 'ciudad_id_sede', 'cliente_id_sede'] Filas: 741\n",
      "Columnas después del merge con ciudad: ['id', 'direccion_origen', 'cliente_id_origen', 'ciudad_id_origen', 'sede_id', 'nombre', 'direccion_sede', 'telefono', 'nombre_contacto', 'ciudad_id_sede', 'cliente_id_sede', 'ciudad_id', 'nombre_ciudad', 'departamento_id'] Filas: 741\n",
      "Dimensión dim_sede creada con 741 filas.\n"
     ]
    }
   ],
   "source": [
    "# --- Dimensión: dim_sede ---\n",
    "# Unimos origen con sede para obtener información de la sede asociada al origen\n",
    "dim_sede = df_origen.merge(df_sede, how=\"left\", left_on=\"id\", right_on=\"sede_id\", suffixes=(\"_origen\", \"_sede\"))\n",
    "print(\"Columnas después del merge con sede:\", dim_sede.columns.tolist(), \"Filas:\", len(dim_sede))\n",
    "        \n",
    "# Unimos con ciudad para obtener el nombre de la ciudad de la sede\n",
    "dim_sede = dim_sede.merge(df_ciudad, how=\"left\", left_on=\"ciudad_id_sede\", right_on=\"ciudad_id\", suffixes=(\"\", \"_ciudad\"))\n",
    "print(\"Columnas después del merge con ciudad:\", dim_sede.columns.tolist(), \"Filas:\", len(dim_sede))\n",
    "        \n",
    "# Seleccionamos columnas relevantes y renombramos para claridad\n",
    "expected_columns = [\"id\", \"sede_id\", \"nombre\", \"ciudad_id_sede\", \"nombre_ciudad\"]\n",
    "available_columns = [col for col in expected_columns if col in dim_sede.columns]\n",
    "if not all(col in dim_sede.columns for col in expected_columns):\n",
    "    missing_columns = [col for col in expected_columns if col not in dim_sede.columns]\n",
    "    print(f\"Columnas faltantes en dim_sede: {missing_columns}\")\n",
    "dim_sede = dim_sede[available_columns].drop_duplicates(subset=[\"id\"])\n",
    "print(\"Dimensión dim_sede creada con\", len(dim_sede), \"filas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39e868b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión dim_cliente creada con 27 filas.\n"
     ]
    }
   ],
   "source": [
    "# --- Dimensión: dim_cliente ---\n",
    "dim_cliente = df_cliente[[\"cliente_id\", \"nit_cliente\", \"nombre\", \"ciudad_id\", \"tipo_cliente_id\"]]\n",
    "dim_cliente = dim_cliente.rename(columns={\n",
    "    \"cliente_id\": \"ID_Cliente\", \"nit_cliente\": \"NIT_Cliente\", \"nombre\": \"Nombre_Cliente\",\n",
    "    \"ciudad_id\": \"ID_Ciudad\", \"tipo_cliente_id\": \"ID_Tipo_Cliente\"\n",
    "}).drop_duplicates(subset=[\"ID_Cliente\"])\n",
    "print(\"Dimensión dim_cliente creada con\", len(dim_cliente), \"filas.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c615dc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión dim_mensajero creada con 50 filas.\n"
     ]
    }
   ],
   "source": [
    "# --- Dimensión: dim_mensajero ---\n",
    "\n",
    "# Unir df_mensajero con df_auth_user para obtener el nombre de usuario\n",
    "dim_mensajero = df_mensajero.merge(\n",
    "\tdf_auth_user, how=\"left\", left_on=\"user_id\", right_on=\"id\"\n",
    ")\n",
    "dim_mensajero = dim_mensajero[[\"id_x\", \"user_id\", \"username\"]].rename(columns={\n",
    "\t\"id_x\": \"ID_Mensajero\", \"user_id\": \"ID_User\", \"username\": \"Nombre_Mensajero\"\n",
    "}).drop_duplicates(subset=[\"ID_Mensajero\"])\n",
    "print(\"Dimensión dim_mensajero creada con\", len(dim_mensajero), \"filas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "accaf8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión dim_estado_servicio creada con 6 filas.\n"
     ]
    }
   ],
   "source": [
    "# --- Dimensión: dim_estado_servicio ---\n",
    "dim_estado_servicio = df_estado[[\"id\", \"nombre\"]].rename(columns={\n",
    "    \"id\": \"ID_Estado\", \"nombre\": \"Nombre_Estado\"\n",
    "})\n",
    "dim_estado_servicio[\"Nombre_Estado\"] = dim_estado_servicio[\"Nombre_Estado\"].fillna(\"Desconocido\")\n",
    "dim_estado_servicio = dim_estado_servicio.drop_duplicates(subset=[\"ID_Estado\"])\n",
    "print(\"Dimensión dim_estado_servicio creada con\", len(dim_estado_servicio), \"filas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2fd86fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión dim_tipo_servicio creada con 4 filas.\n"
     ]
    }
   ],
   "source": [
    "# --- Dimensión: dim_tipo_servicio ---\n",
    "dim_tipo_servicio = df_tipo_servicio[[\"id\", \"nombre\"]].rename(columns={\n",
    "    \"id\": \"ID_Tipo_Servicio\", \"nombre\": \"Nombre_Tipo_Servicio\"\n",
    "})\n",
    "dim_tipo_servicio[\"Nombre_Tipo_Servicio\"] = dim_tipo_servicio[\"Nombre_Tipo_Servicio\"].fillna(\"Desconocido\")\n",
    "dim_tipo_servicio = dim_tipo_servicio.drop_duplicates(subset=[\"ID_Tipo_Servicio\"])\n",
    "print(\"Dimensión dim_tipo_servicio creada con\", len(dim_tipo_servicio), \"filas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dce8ff",
   "metadata": {},
   "source": [
    "Tabla de hechos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "863d1c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas iniciales de mensajeria_servicio: ['ID_Servicio', 'descripcion', 'nombre_solicitante', 'fecha_solicitud', 'hora_solicitud', 'fecha_deseada', 'hora_deseada', 'nombre_recibe', 'telefono_recibe', 'descripcion_pago', 'ida_y_regreso', 'activo', 'novedades', 'cliente_id', 'destino_id', 'mensajero_id', 'origen_id', 'tipo_pago_id', 'tipo_servicio_id', 'tipo_vehiculo_id', 'usuario_id', 'prioridad', 'ciudad_destino_id', 'ciudad_origen_id', 'hora_visto_por_mensajero', 'visto_por_mensajero', 'descripcion_multiples_origenes', 'mensajero2_id', 'mensajero3_id', 'multiples_origenes', 'asignar_mensajero', 'es_prueba', 'descripcion_cancelado'] Filas: 28430\n",
      "Valores nulos en fecha y hora: fecha     0\n",
      "hora     51\n",
      "dtype: int64\n",
      "Columnas después de pivot_table: ['ID_Servicio', 'ID_Cliente', 'ID_Mensajero', 'id_origen', 'id_destino', 'ID_Tipo_Servicio', '1', '2', '3', '4', '5', '6'] Filas: 19984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_14024\\1607933453.py:50: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pivot[f\"Fecha_{nombre}\"] = pd.to_datetime(pivot[estado], errors='coerce').dt.date\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_14024\\1607933453.py:51: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pivot[f\"Hora_{nombre}\"] = pd.to_datetime(pivot[estado], errors='coerce').dt.time\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_14024\\1607933453.py:50: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pivot[f\"Fecha_{nombre}\"] = pd.to_datetime(pivot[estado], errors='coerce').dt.date\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_14024\\1607933453.py:51: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pivot[f\"Hora_{nombre}\"] = pd.to_datetime(pivot[estado], errors='coerce').dt.time\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_14024\\1607933453.py:50: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pivot[f\"Fecha_{nombre}\"] = pd.to_datetime(pivot[estado], errors='coerce').dt.date\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_14024\\1607933453.py:51: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pivot[f\"Hora_{nombre}\"] = pd.to_datetime(pivot[estado], errors='coerce').dt.time\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_14024\\1607933453.py:50: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pivot[f\"Fecha_{nombre}\"] = pd.to_datetime(pivot[estado], errors='coerce').dt.date\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_14024\\1607933453.py:51: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pivot[f\"Hora_{nombre}\"] = pd.to_datetime(pivot[estado], errors='coerce').dt.time\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_14024\\1607933453.py:50: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pivot[f\"Fecha_{nombre}\"] = pd.to_datetime(pivot[estado], errors='coerce').dt.date\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_14024\\1607933453.py:51: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pivot[f\"Hora_{nombre}\"] = pd.to_datetime(pivot[estado], errors='coerce').dt.time\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_14024\\1607933453.py:50: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pivot[f\"Fecha_{nombre}\"] = pd.to_datetime(pivot[estado], errors='coerce').dt.date\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_14024\\1607933453.py:51: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  pivot[f\"Hora_{nombre}\"] = pd.to_datetime(pivot[estado], errors='coerce').dt.time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas después de añadir fechas y horas: ['ID_Servicio', 'ID_Cliente', 'ID_Mensajero', 'id_origen', 'id_destino', 'ID_Tipo_Servicio', 'Fecha_Iniciado', 'Hora_Iniciado', 'Fecha_Asignado', 'Hora_Asignado', 'Fecha_EnTransito', 'Hora_EnTransito', 'Fecha_Recogido', 'Hora_Recogido', 'Fecha_Entregado', 'Hora_Entregado', 'Fecha_Terminado', 'Hora_Terminado'] Filas: 19984\n",
      "Tabla T_hechos creada con 19984 filas.\n",
      "Tabla de hechos generada: {'dim_hora': 24, 'dim_fecha': 1096, 'dim_sede': 741, 'dim_cliente': 27, 'dim_mensajero': 50, 'dim_estado_servicio': 6, 'dim_tipo_servicio': 4, 'T_hechos': 19984}\n"
     ]
    }
   ],
   "source": [
    "# --- Tabla de hechos: T_hechos ---\n",
    "T_hechos = df_servicio.rename(columns={\"id\": \"ID_Servicio\"})\n",
    "print(\"Columnas iniciales de mensajeria_servicio:\", T_hechos.columns.tolist(), \"Filas:\", len(T_hechos))\n",
    "\n",
    "# Uniones con dimensiones relevantes\n",
    "T_hechos = (\n",
    "    T_hechos\n",
    "    .merge(dim_cliente, left_on=\"cliente_id\", right_on=\"ID_Cliente\", how=\"left\")\n",
    "    .merge(dim_mensajero, left_on=\"mensajero_id\", right_on=\"ID_Mensajero\", how=\"left\")\n",
    "    .merge(dim_sede, left_on=\"origen_id\", right_on=\"id\", how=\"left\", suffixes=(\"\", \"_origen\"))\n",
    "    .merge(dim_sede, left_on=\"destino_id\", right_on=\"id\", how=\"left\", suffixes=(\"_origen\", \"_destino\"))\n",
    "    .merge(dim_tipo_servicio, left_on=\"tipo_servicio_id\", right_on=\"ID_Tipo_Servicio\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Unir con estados de servicio\n",
    "T_hechos = T_hechos.merge(\n",
    "    df_estados_servicio, left_on=\"ID_Servicio\", right_on=\"servicio_id\", how=\"left\"\n",
    ")\n",
    "\n",
    "# Procesamiento de fechas y horas\n",
    "T_hechos[\"fecha\"] = pd.to_datetime(T_hechos[\"fecha\"], errors='coerce')\n",
    "T_hechos[\"hora\"] = pd.to_datetime(T_hechos[\"hora\"], format='%H:%M:%S', errors='coerce').dt.time\n",
    "print(\"Valores nulos en fecha y hora:\", T_hechos[[\"fecha\", \"hora\"]].isnull().sum())\n",
    "\n",
    "# Pivot para estados\n",
    "T_hechos[\"id_estado\"] = T_hechos[\"estado_id\"].astype(str).replace(\"nan\", None)\n",
    "T_hechos[\"DateTimeValue\"] = T_hechos.apply(\n",
    "    lambda row: f\"{row['fecha']} {row['hora']}\" if pd.notnull(row['fecha']) and pd.notnull(row['hora']) else None, axis=1\n",
    ")\n",
    "pivot = T_hechos.pivot_table(\n",
    "    index=[\"ID_Servicio\", \"ID_Cliente\", \"ID_Mensajero\", \"id_origen\", \"id_destino\", \"ID_Tipo_Servicio\"],\n",
    "    columns=\"id_estado\",\n",
    "    values=\"DateTimeValue\",\n",
    "    aggfunc=\"last\"\n",
    ").reset_index()\n",
    "print(\"Columnas después de pivot_table:\", pivot.columns.tolist(), \"Filas:\", len(pivot))\n",
    "\n",
    "# Validación de estados esperados\n",
    "expected_states = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "missing = [e for e in expected_states if e not in pivot.columns]\n",
    "if missing:\n",
    "    print(f\"Estados faltantes en la pivot table: {missing}\")\n",
    "estado_map = {str(k): v for k, v in {\n",
    "    1: \"Iniciado\", 2: \"Asignado\", 3: \"EnTransito\", 4: \"Recogido\", 5: \"Entregado\", 6: \"Terminado\"\n",
    "}.items()}\n",
    "# Extraer fechas y horas por estado\n",
    "for estado in expected_states:\n",
    "    if estado in pivot.columns:\n",
    "        nombre = estado_map[estado]\n",
    "        pivot[f\"Fecha_{nombre}\"] = pd.to_datetime(pivot[estado], errors='coerce').dt.date\n",
    "        pivot[f\"Hora_{nombre}\"] = pd.to_datetime(pivot[estado], errors='coerce').dt.time\n",
    "pivot.drop(columns=[e for e in expected_states if e in pivot.columns], inplace=True)\n",
    "print(\"Columnas después de añadir fechas y horas:\", pivot.columns.tolist(), \"Filas:\", len(pivot))\n",
    "\n",
    "# Cálculo de diferencias de tiempo\n",
    "pivot[\"tiempo_total_min\"] = calculate_time_diff(\n",
    "    pivot[\"Fecha_Iniciado\"], pivot[\"Hora_Iniciado\"], \n",
    "    pivot[\"Fecha_Terminado\"], pivot[\"Hora_Terminado\"]\n",
    ")\n",
    "pivot[\"tiempo_asignacion_min\"] = calculate_time_diff(\n",
    "    pivot[\"Fecha_Iniciado\"], pivot[\"Hora_Iniciado\"], \n",
    "    pivot[\"Fecha_Asignado\"], pivot[\"Hora_Asignado\"]\n",
    ")\n",
    "pivot[\"tiempo_recoleccion_min\"] = calculate_time_diff(\n",
    "    pivot[\"Fecha_Asignado\"], pivot[\"Hora_Asignado\"], \n",
    "    pivot[\"Fecha_Recogido\"], pivot[\"Hora_Recogido\"]\n",
    ")\n",
    "pivot[\"tiempo_entrega_min\"] = calculate_time_diff(\n",
    "    pivot[\"Fecha_Recogido\"], pivot[\"Hora_Recogido\"], \n",
    "    pivot[\"Fecha_Entregado\"], pivot[\"Hora_Entregado\"]\n",
    ")\n",
    "pivot[\"tiempo_cierre_min\"] = calculate_time_diff(\n",
    "    pivot[\"Fecha_Entregado\"], pivot[\"Hora_Entregado\"], \n",
    "    pivot[\"Fecha_Terminado\"], pivot[\"Hora_Terminado\"]\n",
    ")\n",
    "print(\"Tabla T_hechos creada con\", len(pivot), \"filas.\")\n",
    "\n",
    "# Diccionario de datos transformados\n",
    "data_trans = {\n",
    "    \"dim_hora\": dim_hora,\n",
    "    \"dim_fecha\": dim_fecha,\n",
    "    \"dim_sede\": dim_sede,\n",
    "    \"dim_cliente\": dim_cliente,\n",
    "    \"dim_mensajero\": dim_mensajero,\n",
    "    \"dim_estado_servicio\": dim_estado_servicio,\n",
    "    \"dim_tipo_servicio\": dim_tipo_servicio,\n",
    "    \"T_hechos\": pivot\n",
    "}\n",
    "print(\"Tabla de hechos generada:\", {k: len(v) for k, v in data_trans.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c88eafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 128402 entries, 0 to 128401\n",
      "Data columns (total 64 columns):\n",
      " #   Column                          Non-Null Count   Dtype         \n",
      "---  ------                          --------------   -----         \n",
      " 0   ID_Servicio                     128402 non-null  int64         \n",
      " 1   descripcion                     128402 non-null  object        \n",
      " 2   nombre_solicitante              128402 non-null  object        \n",
      " 3   fecha_solicitud                 128402 non-null  object        \n",
      " 4   hora_solicitud                  128402 non-null  object        \n",
      " 5   fecha_deseada                   128402 non-null  object        \n",
      " 6   hora_deseada                    128402 non-null  object        \n",
      " 7   nombre_recibe                   128402 non-null  object        \n",
      " 8   telefono_recibe                 128402 non-null  object        \n",
      " 9   descripcion_pago                127012 non-null  object        \n",
      " 10  ida_y_regreso                   128402 non-null  bool          \n",
      " 11  activo                          128402 non-null  bool          \n",
      " 12  novedades                       126583 non-null  object        \n",
      " 13  cliente_id                      128402 non-null  int64         \n",
      " 14  destino_id                      128402 non-null  int64         \n",
      " 15  mensajero_id                    127675 non-null  float64       \n",
      " 16  origen_id                       128402 non-null  int64         \n",
      " 17  tipo_pago_id                    128402 non-null  int64         \n",
      " 18  tipo_servicio_id                128402 non-null  int64         \n",
      " 19  tipo_vehiculo_id                128402 non-null  int64         \n",
      " 20  usuario_id                      128402 non-null  int64         \n",
      " 21  prioridad                       128402 non-null  object        \n",
      " 22  ciudad_destino_id               128402 non-null  int64         \n",
      " 23  ciudad_origen_id                128402 non-null  int64         \n",
      " 24  hora_visto_por_mensajero        2 non-null       object        \n",
      " 25  visto_por_mensajero             126583 non-null  object        \n",
      " 26  descripcion_multiples_origenes  124410 non-null  object        \n",
      " 27  mensajero2_id                   15276 non-null   float64       \n",
      " 28  mensajero3_id                   2376 non-null    float64       \n",
      " 29  multiples_origenes              128402 non-null  bool          \n",
      " 30  asignar_mensajero               128402 non-null  bool          \n",
      " 31  es_prueba_x                     128402 non-null  bool          \n",
      " 32  descripcion_cancelado           126593 non-null  object        \n",
      " 33  ID_Cliente                      128402 non-null  int64         \n",
      " 34  NIT_Cliente                     128402 non-null  object        \n",
      " 35  Nombre_Cliente                  128402 non-null  object        \n",
      " 36  ID_Ciudad                       128402 non-null  int64         \n",
      " 37  ID_Tipo_Cliente                 128402 non-null  int64         \n",
      " 38  ID_Mensajero                    127675 non-null  float64       \n",
      " 39  ID_User                         127675 non-null  float64       \n",
      " 40  Nombre_Mensajero                127675 non-null  object        \n",
      " 41  id_origen                       128402 non-null  int64         \n",
      " 42  sede_id_origen                  63560 non-null   float64       \n",
      " 43  nombre_origen                   63560 non-null   object        \n",
      " 44  ciudad_id_sede_origen           63560 non-null   float64       \n",
      " 45  nombre_ciudad_origen            63560 non-null   object        \n",
      " 46  id_destino                      92440 non-null   float64       \n",
      " 47  sede_id_destino                 25663 non-null   float64       \n",
      " 48  nombre_destino                  25663 non-null   object        \n",
      " 49  ciudad_id_sede_destino          25663 non-null   float64       \n",
      " 50  nombre_ciudad_destino           25663 non-null   object        \n",
      " 51  ID_Tipo_Servicio                128402 non-null  int64         \n",
      " 52  Nombre_Tipo_Servicio            128402 non-null  object        \n",
      " 53  id                              128402 non-null  int64         \n",
      " 54  fecha                           128402 non-null  datetime64[ns]\n",
      " 55  hora                            128351 non-null  object        \n",
      " 56  foto                            128402 non-null  object        \n",
      " 57  observaciones                   128401 non-null  object        \n",
      " 58  estado_id                       128402 non-null  int64         \n",
      " 59  servicio_id                     128402 non-null  int64         \n",
      " 60  es_prueba_y                     128402 non-null  bool          \n",
      " 61  foto_binary                     270 non-null     object        \n",
      " 62  id_estado                       128402 non-null  object        \n",
      " 63  DateTimeValue                   128351 non-null  object        \n",
      "dtypes: bool(6), datetime64[ns](1), float64(10), int64(18), object(29)\n",
      "memory usage: 57.6+ MB\n"
     ]
    }
   ],
   "source": [
    "T_hechos.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeec48e",
   "metadata": {},
   "source": [
    "Carga de Dimensiones y tabla de hechos a POSTGRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "534a3911",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "usuario = \"fabio\"\n",
    "clave = \"fabio\"\n",
    "host = \"localhost\"\n",
    "puerto = \"5432\"\n",
    "bd = \"DimProyecto\"\n",
    "\n",
    "engine = create_engine(f\"postgresql+psycopg2://{usuario}:{clave}@{host}:{puerto}/{bd}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2b6718a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla 'dim_hora' cargada\n",
      "Tabla 'dim_fecha' cargada\n",
      "Tabla 'dim_sede' cargada\n",
      "Tabla 'dim_cliente' cargada\n",
      "Tabla 'dim_mensajero' cargada\n",
      "Tabla 'dim_estado_servicio' cargada\n",
      "Tabla 'dim_tipo_servicio' cargada\n",
      "Tabla 'T_hechos' cargada\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Carga de tablas\n",
    "for nombre_tabla, df in data_trans.items():\n",
    "    df.to_sql(nombre_tabla, engine, if_exists='replace', index=False)\n",
    "    print(f\"Tabla '{nombre_tabla}' cargada\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
